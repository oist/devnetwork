THREADS = 20
REF = "../ref/amel_ref_reordered.fa"
GFF = "../ref/amel_reoriented.gff"
PICARD = "/home/warnerm/local_install/picard.jar"

PLATYPUS = "/home/warnerm/local_install/Platypus_0.8.1/Platypus.py"
CALLER=["freebayes","platypus","samtools","GATK"]
STAGE = ["larva","pupa","head","thorax","abdomen"]

GROUPS, = glob_wildcards("../var/apis_bigStudy/{group}.vcf")


rule all:
	input: expand("../out/reordered_alpha_locusF_{stage}.bee.csv",stage=STAGE),
			"../out/MKtest_globalAlpha_locusF_bee_reordered",
			"../out/apis_reordered.gene.pi.csv"


rule buildBowtie:
	input: REF
	output: "../ref/amel_reordered.1.bt2"
	shell: "bowtie2-build {REF} ../ref/amel_reordered"

#Download Apis cerana
rule downloadData:
	output: "../data/fastq/SRR957079_pass.fastq"
	shell: "python2.7 download_data.py SRR957079"

rule alignReads:
	input: rules.buildBowtie.output,rules.downloadData.output
	output: "../temp/amel_reordered_alignments/SRR957079.bam"
	shell: """bowtie2 -x ../ref/amel_reordered -U {input[1]} -p {THREADS} | samtools view -bSF4 > {output}"""

#Sorts the bam files; necessary for at least samtools
rule PicardGroups:
	input: "../temp/amel_reordered_alignments/SRR957079.bam"
	output: "../temp/amel_reordered_alignments/SRR957079_RG.bam"
	shell: """java -jar {PICARD} AddOrReplaceReadGroups I={input} O={output} SORT_ORDER=coordinate \
				CREATE_INDEX=true RGPL=illumina RGID=cerana RGSM=cerana RGLB=lib1 RGPU=unit1"""

rule makeBED:
	input: GFF
	output: "../ref/amel_reordered_exons.bed"
	shell: """grep "exon" {GFF} | gff2bed > {output}"""

rule makeDict:
	input: REF
	output: "../ref/amel_ref_reordered.dict"
	shell: "java -jar {PICARD} CreateSequenceDictionary R={input} O={output}"

	#Split up targets to run freebayes and gatk in parallel
rule subset_exons:
	input: "../ref/amel_reordered_exons.bed"
	output: expand("../ref/amel_reordered_subEx_{i}.bed",i=range(20))
	run:
		for i in range(20):
			f = output[i]
			numL = 11610*(i+1)
			shell("head -n {numL} {input} | tail -n 11610 > {f}")

#'-=' means report genome qualities, the params makes a list of input files, min-alternate-count sets minimum number of chromosomes sampled to consider an allele
#Using target= exons.bed because we only want to call variants for exons
rule freeBayes:
	input: rules.PicardGroups.output,bed="../ref/amel_reordered_subEx_{i}.bed"
	output: "../var/amel_reordered_fb_{i}.vcf"
	shell: "freebayes -= -b {input[0]} -v {output} -f {REF} --min-alternate-count 4 --use-best-n-alleles 3 --targets {input[bed]}"

rule mergeFB:
	input: expand("../var/amel_reordered_fb_{i}.vcf",i=range(20))
	output: "../var/amel_reordered_freebayes.vcf"
	shell: "vcf-concat {input} > {output}"

#Just get first three columns of bed files for GATK
rule editBed:
	input: "../ref/amel_reordered_subEx_{i}.bed"
	output: "../ref/amel_reordered_subEx_{i}_edit.bed"
	shell: """cat {input} | awk '{{print$1"\t"$2"\t"$3}}' > {output}"""

#Convert bed files to interval lists for gatk
rule intervalList:
	input: "../ref/amel_ref_reordered.dict",bed="../ref/amel_reordered_subEx_{i}_edit.bed",
	output: "../ref/amel_reordered_subEx_{i}.interval_list"
	shell: """export PATH=~/local_install/jdk1.8.0_05/bin:$PATH; java -jar {PICARD} BedToIntervalList I={input[bed]} O={output} SD={input[0]}"""

rule GATK:
	input: rules.PicardGroups.output,intervals= "../ref/amel_reordered_subEx_{i}.interval_list"
	output: "../var/amel_reordered_gatk_{i}.vcf"
	shell: """export PATH=~/local_install/jdk1.8.0_05/bin:$PATH; gatk --java-options "-Xmx30g" HaplotypeCaller \
				-R {REF} \
				-I {input[0]} \
				-O {output} \
				-L {input[intervals]} \
				--heterozygosity 0.002 \
				--mbq 20 \
				--max-alternate-alleles 4"""

rule mergeGATK:
	input: expand("../var/amel_reordered_gatk_{i}.vcf",i=range(20))
	output: "../var/amel_reordered_GATK.vcf"
	shell: "vcf-concat {input} > {output}"

rule samtools:
	input: rules.PicardGroups.output,rules.makeBED.output
	output: "../var/amel_reordered_samtools.vcf"
	shell: "samtools mpileup -l {input[1]} -ugf {REF} {input[0]} | bcftools call -vc - | vcfutils.pl varFilter -D 500 > {output}"

rule platypus:
	input: rules.PicardGroups.output,rules.makeBED.output
	output: "../var/amel_reordered_platypus.vcf"
	shell: "python2.7 {PLATYPUS} callVariants --nCPU={THREADS} --refFile={REF} --bamFiles={input[0]} --output={output} --maxReads=25000000 --regions={input[1]}"

#remove insertions and deletions
rule rmIndel:
	input: "../var/amel_reordered_{VCFcaller}.vcf"
	output: "../var/amel_reordered_{VCFcaller}.snp.recode.vcf"
	shell: "vcftools --vcf {input} --remove-indels --out ../var/amel_reordered_{wildcards.VCFcaller}.snp --recode --recode-INFO-all"

rule allelicPrimitives:
	input: "../var/amel_reordered_{VCFcaller}.snp.recode.vcf"
	output: "../var/amel_reordered_{VCFcaller}.snp.primatives.vcf"
	shell: "cat {input} | vcfallelicprimitives -kg > {output}"

rule vcfSort:
	input: "../var/amel_reordered_{VCFcaller}.snp.primatives.vcf"
	output: "../var/amel_reordered_{VCFcaller}.snp.primatives.sorted.vcf"
	shell: "vcf-sort {input} > {output}"

# generate consensus SNP calls
rule BAYSIC: 	
	input: expand("../var/amel_reordered_{VCFcaller}.snp.primatives.sorted.vcf", VCFcaller=CALLER)
	output: "../var/amel_reordered_consensus.vcf.pos","../var/amel_reordered_consensus.vcf"
	run: 
		infiles = "".join([" --vcf " + i for i in input])
		shell("perl baysic.pl --statsOutFile ../var/combined.stats --pvalCutoff 0.8 {} --countsOutFile ../var/amel_reordered_combined.cts --vcfOutFile ../var/amel_reordered_consensus.vcf".format(infiles))

# select bi-allelic consensus sites
rule consensusFilter:
     input: "../var/amel_reordered_freebayes.snp.primatives.sorted.vcf","../var/amel_reordered_consensus.vcf.pos"
     output: "../var/amel_reordered_final.recode.vcf"
     shell: "vcftools --vcf {input[0]} --positions {input[1]} --max-alleles 2 --remove-indels --max-missing 0.9 --recode --mac 1 --out  ../var/amel_reordered_final"

#rename Groups to LG to match other vcf files
rule renameVCF:
	input: rules.consensusFilter.output
	output: "../var/amel_reordered_edit.recode.vcf"
	shell: "sed 's/Group/LG/' {input} | vcf-sort > {output}"

#combine vcfs among groups
rule combineVCF:
	input: expand("../var/apis_bigStudy/{group}.vcf",group=GROUPS)
	output: "../var/amel_reordered_allGroups.vcf"
	shell: "vcf-concat {input} | vcf-sort > {output}"

#remove insertions and deletions
rule rmIndel_all:
	input: "../var/amel_reordered_allGroups.vcf"
	output: "../var/amel_reordered_allGroups.snp.recode.vcf"
	shell: "vcftools --vcf {input} --remove-indels --out ../var/amel_reordered_allGroups.snp --recode --recode-INFO-all"

rule allelicPrimitives_all:
	input: "../var/amel_reordered_allGroups.snp.recode.vcf"
	output: "../var/amel_reordered_allGroups.snp.primatives.vcf"
	shell: "cat {input} | vcfallelicprimitives -kg > {output}"

rule vcfSort_all:
	input: "../var/amel_reordered_allGroups.snp.primatives.vcf"
	output: "../var/amel_reordered_allGroups.snp.primatives.sorted.vcf"
	shell: "vcf-sort {input} > {output}"

#The vcf files have some conflicting reference alleles. Remove these sites
rule removeConflicts:
	input: rules.renameVCF.output,rules.vcfSort_all.output
	output: "../var/amel_reordered_cerana_noconflict.vcf","../var/amel_reordered_group_noconflict.vcf"
	shell: "python2.7 removeMismatch.py {input} {output}"

rule tabixCerana:
	input: "../var/amel_reordered_cerana_noconflict.vcf"
	output: "../var/amel_reordered_cerana_noconflict.vcf.gz.tbi"
	shell: "bgzip {input}; tabix -p vcf {input}.gz"

rule tabixAllVCF:
	input: "../var/amel_reordered_group_noconflict.vcf"
	output: "../var/amel_reordered_group_noconflict.vcf.gz.tbi"
	shell: "bgzip {input}; tabix -p vcf {input}.gz"

#Add cerana (outgroup) to vcf
rule addCerana:
	input: rules.tabixCerana.output,rules.tabixAllVCF.output
	output: "../var/amel_reordered_allGroups_plusCerana.vcf"
	shell: "bcftools merge ../var/amel_reordered_cerana_noconflict.vcf.gz ../var/amel_reordered_group_noconflict.vcf.gz > {output}"

# estimate SNP effects
rule snpEff:
	input: rules.addCerana.output
	output: "../var/snpEff_reordered.txt"
	shell: "java -Xmx7g -jar /home/warnerm/local_install/snpEff/snpEff.jar -no-utr -no-upstream -no-intron -no-intergenic -no-downstream amel_reordered {input} >  {output}"

# determine which SNPs are fixed and which are polymorphic
# for this we remove the outgroup and compute frequencies
#Apis cerana is SRR957079
rule fixedPolymorphic:	
	input: rules.addCerana.output
	output: "../var/snps_reordered.csv"
	shell: """vcftools --vcf {input} --remove-indv cerana --freq; \
    awk -v OFS="," ' NR>1 {{split($5,a,":"); if((a[2]=="1") || (a[2]=="0")) state="F"; else state="P"; print $1,$2,state}}' out.frq > {output} """

rule getCDS:
	input: GFF, REF
	output: "../ref/cds_reordered.fa"
	shell: "gffread {input[0]} -g {input[1]} -x {output}"

rule filterLongest:
	input: rules.getCDS.output
	output: "../ref/longest_reordered.fa"
	shell: "python filter_longest.py {input} > {output}"

# exports silent and replacement sites from snpEff
rule parseSilentReplacement:
	input: rules.filterLongest.output, rules.snpEff.output
	output: "../var/annotation_reordered.csv"
	shell: "python2.7 parse_silentReplacement.py {input} > {output}"

# calculate how many synonymous vs_non-synonymous changes are possible
rule silentReplacement:
	input: rules.filterLongest.output
	output: "../var/silentReplacement_reordered.csv"
	shell: "python2.7 silent_replacement.py {input} > {output}"

#Tabulate substitutions
rule tab_subs:
	input: rules.parseSilentReplacement.output,rules.fixedPolymorphic.output,rules.silentReplacement.output
	output: "../out/substitutions_reordered.csv"
	shell: "Rscript --vanilla tabulate_substitutions.R {input} {output}"

#rule snipre:
#	input: rules.silentReplacement.output, rules.parseSilentReplacement.output,rules.fixedPolymorphic.output
#	output: "../out/bayesian_results_apis_reordered.csv"
#	shell: "Rscript --vanilla snipre.R {input} {output}"

#Make MKinput files for alpha classes (both species)
rule MKclass_input:
	input: "../out/substitutions_reordered.csv","../data/DEtests.RData","../data/MpharAnn.csv"
	output: expand("../MK_alpha_input/reordered_{stage}.bee.csv",stage=STAGE),"../MK_alpha_input/old_abd.csv"
	shell: "Rscript MKalphaInput.R ../MK_alpha_input/reordered_"

#Calculate constraint from MKtest
rule MKtest_constraint:
	input: "../MK_alpha_input/reordered_abdomen.bee.csv"
	output: "../out/MKtest_globalAlpha_locusF_bee_reordered"
	shell: "MKtest -a 1 -f 2 -o {output} {input}"

#Bootstrap MKtest for alpha results (class-specific alpha)
rule MKtest_alpha:
	input: "../MK_alpha_input/reordered_{stage}.bee.csv"
	output: "../out/reordered_alpha_locusF_{stage}.bee.csv"
	shell: "MKtest -a 3 -f 2 -o {output} {input}"


#Combine alpha results
#rule combineMK:
#	input: expand("../out/reordered_alpha_locusF_{stage}.bee_reordered.csv",stage=STAGE)
#	output: "../out/collectedAlpha_bee_reordered.csv"
#	shell: "Rscript combineAlpha.R ../out/reordered_alpha_locusF_ {output}"

#Calculate pi within honeybee population
rule calcPi:
	input: rules.addCerana.output
	output: "../out/apis_reordered.sites.pi"
	shell: "vcftools --vcf {input} --site-pi --remove-indv cerana --out ../out/apis_reordered"

#Calculate gene-wise pi
rule genePi:
	input: rules.parseSilentReplacement.output,rules.calcPi.output
	output: "../out/apis_reordered.gene.pi.csv"
	shell: "Rscript --vanilla pi_per_gene.R {input} {output}"


















