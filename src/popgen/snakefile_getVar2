'''
#Software
GATK version 4.0.5.2
Platypus version 0.8.1
samtools version 1.7, htslib version 1.7.2
freebayes v1.2.0
vcftools
Baysic v1.0
bedtools v2.26.0
'''
SAMPLES, = glob_wildcards("../temp/alignments/africa_cerana/no_read_group/{sample}.bam")
PICARD = "/home/warnerm/local_install/picard.jar"

REF = "../ref/GCF_000002195.4_Amel_4.5_genomic.fna"
GFF = "../ref/GCF_000002195.4_Amel_4.5_genomic.gff"
THREADS = 20
PLATYPUS = "/home/warnerm/local_install/Platypus_0.8.1/Platypus.py"
CALLER=["freebayes"]
INDEX = [0,1,2,3]

rule all:
	input: "../var/freebayes.vcf"

rule makeBED:
	input: GFF
	output: "../ref/exons.bed"
	shell: """grep "exon" {GFF} | gff2bed > {output}"""

rule makeDict:
	input: REF
	output: "../ref/GCF_000002195.4_Amel_4.5_genomic.dict"
	shell: "java -jar {PICARD} CreateSequenceDictionary R={input} O={output}"

#Sorts the bam files; necessary for at least samtools
rule PicardGroups:
	input: "../temp/alignments/africa_cerana/no_read_group/{sample}.bam"
	output: "../temp/alignments/africa_cerana/rg_added/{sample}.bam"
	shell: """java -jar {PICARD} AddOrReplaceReadGroups I={input} O={output} SORT_ORDER=coordinate \
				CREATE_INDEX=true RGPL=illumina RGID={wildcards.sampled} RGSM={wildcards.sample} RGLB=lib1 RGPU=unit1"""


#Split up targets to run freebayes and gatk in parallel
rule subset_exons:
	input: "../ref/exons.bed"
	output: expand("../ref/subEx_{i}.bed",i=range(20))
	run:
		for i in range(20):
			f = output[i]
			numL = 11610*(i+1)
			shell("head -n {numL} {input} | tail -n 11610 > {f}")

#'-=' means report genome qualities, the params makes a list of input files, min-alternate-count sets minimum number of chromosomes sampled to consider an allele
#Using target= exons.bed because we only want to call variants for exons
rule freeBayes:
	input: expand("../temp/alignments/africa_cerana/rg_added/{sample}.bam",sample=SAMPLES),rules.subset_exons.output
	output: expand("../var/fb_{index}.vcf",index=INDEX)
	params: 
		files = "-b " + " -b ".join(expand("../temp/alignments/africa_cerana/rg_added/{sample}.bam",sample=SAMPLES)),
	threads: 20
	run:
		for i in range(20):
			f = output[i]
			shell("freebayes -= {params.files} -v {f} -f {REF} --min-alternate-count 4 --use-best-n-alleles 3 --targets ../ref/subEx_$i.bed")

rule mergeFB:
	input: rules.freeBayes.output
	output: "../var/freebayes.vcf"
	shell: "cat ../var/fb*vcf > {output}"

#rule GATK:
#	input: expand("../temp/alignments/africa_cerana/rg_added/{sample}.bam",sample=SAMPLES),bed = "../ref/exons.bed",dict="../ref/GCF_000002195.4_Amel_4.5_genomic.dict"
#	output: protected("../var/GATK.vcf")
#	params: files = "-I " + " -I ".join(expand("../temp/alignments/africa_cerana/rg_added/{sample}.bam",sample=SAMPLES))
#	shell: """export PATH=~/local_install/jdk1.8.0_05/bin:$PATH; gatk --java-options "-Xmx30g" HaplotypeCaller \
#				-R {REF} \
#				{params.files} \
#				-O {output} \
#				-L ../ref/exons.bed \
#				--heterozygosity 0.002 \
#				--mbq 20 \
#				--max-alternate-alleles 4"""

rule samtools:
	input: BAMs = expand("../temp/alignments/africa_cerana/rg_added/{sample}.bam",sample=SAMPLES),bed = "../ref/exons.bed"
	output: "../var/samtools.vcf"
	shell: "samtools mpileup -l {input[bed]} -ugf {REF} {input[BAMs]} | bcftools call -vc - | vcfutils.pl varFilter -D 500 > {output}"


rule platypus:
	input: expand("../temp/alignments/africa_cerana/rg_added/{sample}.bam",sample=SAMPLES),bed = "../ref/exons.bed"
	output: "../var/platypus.vcf"
	params: files = ",".join(expand("../temp/alignments/africa_cerana/rg_added/{sample}.bam",sample=SAMPLES))
	shell: "python2.7 {PLATYPUS} callVariants --nCPU={THREADS} --refFile={REF} --bamFiles={params.files} --output={output} --maxReads=25000000 --regions=../ref/exons.bed"

#remove insertions and deletions
rule rmIndel:
	input: "../var/{VCFcaller}.vcf"
	output: "../var/{VCFcaller}.snp.recode.vcf"
	shell: "vcftools --vcf {input} --remove-indels --out ../var/{wildcards.VCFcaller}.snp --recode --recode-INFO-all"

rule allelicPrimitives:
	input: "../var/{VCFcaller}.snp.recode.vcf"
	output: "../var/{VCFcaller}.snp.primatives.vcf"
	shell: "cat {input} | vcfallelicprimitives -kg > {output}"

rule vcfSort:
	input: "../var/{VCFcaller}.snp.primatives.vcf"
	output: "../var/{VCFcaller}.snp.primatives.sorted.vcf"
	shell: "vcf-sort {input} > {output}"

# generate consensus SNP calls
rule BAYSIC: 	
	input: expand("../var/{VCFcaller}.snp.primatives.sorted.vcf", VCFcaller=CALLER)
	output: "../var/consensus.vcf.pos","../var/consensus.vcf"
	run: 
		infiles = "".join([" --vcf " + i for i in input])
		shell("perl baysic.pl --statsOutFile ../var/combined.stats --pvalCutoff 0.8 {} --countsOutFile ../var/combined.cts --vcfOutFile {output[1}".format(infiles))

# select bi-allelic consensus sites
rule consensusFilter:
     input: "../var/consensus.vcf","../var/consensus.vcf.pos"
     output: "../var/final.recode.vcf"
     shell: "vcftools --vcf {input[0]} --positions {input[1]} --max-alleles 2 --remove-indels --max-missing 0.9 --recode --mac 1 --out  ../var/final"

# estimate SNP effects
rule snpEff:
	input: rules.consensusFilter.output
	output: "../var/snpEff.txt"
	shell: "java -Xmx7g -jar /home/warnerm/local_install/snpEff/snpEff.jar -no-utr -no-upstream -no-intron -no-intergenic -no-downstream a_mellifera {input} >  {output}"

# determine which SNPs are fixed and which are polymorphic
# for this we remove the outgroup and compute frequencies
#Apis cerana is SRR957079
rule fixedPolymorphic:	
	input: rules.consensusFilter.output
	output: "../var/snps.csv"
	shell: """vcftools --vcf {input} --remove-indv SRR957079 --freq; \
    awk -v OFS="," ' NR>1 {{split($5,a,":"); if((a[2]=="1") || (a[2]=="0")) state="F"; else state="P"; print $1,$2,state}}' out.frq > {output} """

rule getCDS:
	input: GFF, REF
	output: "../ref/cds.fa"
	shell: "gffread {input[0]} -g {input[1]} -x {output}"

rule filterLongest:
	input: rules.getCDS.output
	output: "../ref/longest.fa"
	shell: "python filter_longest.py {input} > {output}"


